{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 'abc']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [\"a\", \"b\", \"12\", \"cde\"]\n",
    "\n",
    "\n",
    "def functie(lista: list):\n",
    "    lista = [1, 2, \"abc\"]\n",
    "    new_list = []\n",
    "    for i in lista:\n",
    "        new_list.append(i)\n",
    "\n",
    "    return new_list\n",
    "\n",
    "\n",
    "functie(lista)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the training data\n",
    "with open(\"cartarescushort.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "text = \" \".join(lines)  # Merge lines into a single string\n",
    "text = text.lower()  # Convert text to lowercase\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "sequences = tokenizer.texts_to_sequences([text])[0]\n",
    "word_index = tokenizer.word_index\n",
    "index_word = {index: word for word, index in word_index.items()}\n",
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "max_len = 40  # Length of input sequences\n",
    "step = 3  # Stride between input sequences\n",
    "sentences = []\n",
    "next_words = []\n",
    "for i in range(0, len(sequences) - max_len, step):\n",
    "    sentences.append(sequences[i: i + max_len])\n",
    "    next_words.append(sequences[i + max_len])\n",
    "\n",
    "# Convert the data into input-output pairs\n",
    "X = np.array(sentences)\n",
    "y = np.array(next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=max_len))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "def generate_text(temperature=0.5):\n",
    "    start_index = random.randint(0, len(sequences) - max_len - 1)\n",
    "    generated_sequence = sequences[start_index: start_index + max_len]\n",
    "    generated_text = \" \".join([index_word[index] for index in generated_sequence])\n",
    "    sys.stdout.write(generated_text)\n",
    "\n",
    "    for _ in range(100):\n",
    "        x_pred = pad_sequences([generated_sequence], maxlen=max_len)\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        next_index = np.random.choice(range(vocab_size), p=preds)\n",
    "        next_word = index_word[next_index]\n",
    "\n",
    "        generated_sequence = np.append(generated_sequence[1:], next_index)\n",
    "        generated_text += \" \" + next_word\n",
    "\n",
    "        if next_word in string.punctuation:\n",
    "            sys.stdout.write(next_word)\n",
    "        else:\n",
    "            sys.stdout.write(\" \" + next_word)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating text after Epoch: 1\n",
      "142/142 [==============================] - 77s 518ms/step - loss: 7.9145\n",
      "nu mai aveam scăpare panica mi a crescut deodată până la un paroxism insuportabil am luat o la fugă prin halambeznată doar cu stelele arzând prin găurile acoperişului m am împiedicat de câteva ori de venele gofrate de sub podea la de cu cu de se cu şi să şi pe în cu de mai îi de ce care care de de de n de vorbea mai a în e de în de în un o a de de în de de se de şi de în să şi de o şi cu de a de de de vreodată a că de şi mai să şi de de de de de şi de să a pe de a să şi să şi şi de de de şi mai şi în pe o cu am mi care de de de ai\n",
      "----- Generating text after Epoch: 2\n",
      "142/142 [==============================] - 82s 577ms/step - loss: 7.1206\n",
      "prin faptul că eram doi copii la fel spectaculoşi cum unul singur n ar fi putut fi se estompa în amintirea tuturor cum se estompa şi fiinţa dublă a gemenilor familiei noastre rămăsesem eu singur iubit cum n aveam să în şi şi ca de cu ca pe cu de cu de şi cu de de care cu mai de de de care când şi de şi de de un să şi şi de în din de care de pe a care de şi şi cu de nu mai au de o de de de a de şi de am o în şi în de în să în la de de el de pe de acum de de de şi cu să şi de pe nu în şi cu pe ar să cu şi şi de de şi de o\n",
      "----- Generating text after Epoch: 3\n",
      "142/142 [==============================] - 84s 594ms/step - loss: 7.0039\n",
      "culcam doar când auzeam primele tramvaie trecând pe ştefan cel mare nu aveam nici un prieten când singurătatea şi disperarea îmi deveneau insuportabile ieşeam la plimbare pe străzi lăturalnice necunoscute cu case vechi negustoreşti pline de amoraşi şi gorgone de de ca de spumă de cum şi la o podea şi din o aproape care de care să am a vin în şi că de şi cu curat prin la întunericul am am meu la se viaţa ca de de cărţi să ca în că de de asta cu e de la pe în a sub de am se veşnicii în de toată un târgoveţi se fotograf de în nu de şi şi de între pe după se care şi de ar cu ce de şi şi şi de cu cu de şi cu în când se când din de\n",
      "----- Generating text after Epoch: 4\n",
      "142/142 [==============================] - 86s 603ms/step - loss: 6.8440\n",
      "marile mele plăceri era să asist la desfacerea aparatului ceremonie care avea mereu solemnitatea unei operaţii complicate cu pacientul deschis având toate organele la vedere mai întâi mutam televizorul surprinzător de greu pe masa rabatabilă din sufragerie pe care jucam la mine o fi are de discretă din etaj îmi la anatomic de odată şi pe dacă care şi pe care de şi de oarbe în de leneş pe le orice de nu de se trântit de aş să o scriam reviste de acum în jos de miroseau în şi de cărnii şi am îmi atinsă şi de martirizată o sub că de mintea şi pe fugă de branhiile şi o puteau ca şi se mari la aprinsă şi cu în după meu şi de cu dimineaţă şi de sunt în pot şi nu de se gemenilor pe de aş\n",
      "----- Generating text after Epoch: 5\n",
      "142/142 [==============================] - 84s 593ms/step - loss: 6.6932\n",
      "așezate în ordine alfabetică erau pentru mine asemenea acelor panouri cu cutii poştale care ocupă la parterul blocurilor câte un perete întreg de câte ori nu mi dorisem când eram copil să am cheile tuturor cutiilor mi aş fi petrecut de avea de degetul de când să mai magneţi…construise nu un îndepărtată acum un după voluptate de o îmi plută în care fără de de când pe se poartă l acolo de au dat în mine de la subţire pe să şi un tinichigiii ce şi nu dar de stat o de mai treia când ca de ani cu o clasa de pe fisură de care era să mi o fi liţă fusesem de care şi să mi să nu când pe nu un ard cusut el cu care de o uşii mi să nu şi din scriu de şi\n",
      "----- Generating text after Epoch: 6\n",
      "142/142 [==============================] - 80s 564ms/step - loss: 6.5596\n",
      "râul colentina unde doarme pe o saltea locatarii îl lasă acolo de milă şi chiar îi dau voie să doarmă în apartamentele lor dacă sunt plecaţi vreme mai îndelungată fiindcă bătrânul pileşte cât poate dar nu pune mâna nici pe mă deschis şi n baltă de nu sunt un care să o lase că de la verde şi nu o care cu lumea pe am „medicinei de la deasupra cu şi unde de n la la lui o un ani şi aveam a atât de a nenoroc de care în care cu de totul şi mai fost la care în care şi se o fost nu de doar şi a fost de mai multă trăiesc care a era o fac să în fi ani pe n dintr de la care de mi din fost şi a mai străvechi fusesem şi\n",
      "----- Generating text after Epoch: 7\n",
      " 82/142 [================>.............] - ETA: 36s - loss: 6.3989"
     ]
    }
   ],
   "source": [
    "# Train the model and generate text after each epoch\n",
    "for epoch in range(1, 11):\n",
    "    print(\"\\n----- Generating text after Epoch: %d\" % epoch)\n",
    "    model.fit(X, y, batch_size=128, epochs=1)\n",
    "    generate_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f17abcb135fb93cba57d251f948c963432480f4be11000e9d00ee8b9265f85a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
